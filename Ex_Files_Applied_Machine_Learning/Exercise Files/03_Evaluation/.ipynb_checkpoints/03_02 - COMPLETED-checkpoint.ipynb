{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring Success: Splitting up the data for train, validation, and test set\n",
    "\n",
    "Split the dataset up into the following segments:\n",
    "1. Training Data: 60%\n",
    "2. Validation Data: 20%\n",
    "3. Test Data: 20%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data\n",
    "\n",
    "_Welcome back, in this lesson we're going to take what we discussed in the last section and actually implement it._\n",
    "\n",
    "_So we will start by importing the packages we'll need and reading in our data - I'll just call your attention to the `train test split` method we're importing from `sklearn` - that will make our job here **very** easy._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "titanic = pd.read_csv('../titanic.csv')\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into train, validation, and test set\n",
    "\n",
    "_Now, to split into train, validation, and test set. We need to start by splitting our data into our features (the fields used to make a prediction) and our labels or target variable (in our case that's whether somebody survived or not)._\n",
    "\n",
    "_Next, we will call our `train test split` method and first we need to pass in our features, then we'll pass in our labels, we tell it what percent of the dataset we want allocated to the test set, and lastly `random state` is just the initialization seed for the randomizer (don't need to discuss here). So now you might be wondering why I'm indicating test size of 40%? Well, `train test split` doesn't have the functionality to split into three datasets. So we'll handle this in two steps. Allocate 60% to training and 40% to which it's calling \"test\". Then we will take that 40% and split it in half and that will give us our 60% training, 20% validation, 20% test set._\n",
    "\n",
    "_Now first, we need to name the outputs `train test split` will give us. So it will output 4 datasets: it takes features and labels and splits each of them into train and test. So the output is `X train`, `X test`, `y train`, `y test`. AND IT IS IN THIS ORDER - THIS IS VERY IMPORTANT. And `train test split` will correlate between features and labels so the same examples that are in `X train` are in `y train` and in the same order - same for the test._\n",
    "\n",
    "_Now, lets take that test set and split it into validation and test. So we will copy and paste down. Change `features` to `X test`, change `labels` to `y test`, and change `test size` to 50%. So we're taking the 40% of the full dataset that we assigned to the test set and we're splitting it in half to create our validation set and test set. Now, lets update the output names. We'll say `X test`, `X val`, `y test`, and `y val`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = titanic.drop('Survived', axis=1)\n",
    "labels = titanic['Survived']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.4, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Now, lets quickly take a look at the length of each of these datasets to make sure that 60% went to train and 20% to each test and validation. So print out the length of `labels` (full dataset), length of `y train`, length of `y val`, and length of `y test`._\n",
    "\n",
    "_And we can confirm that it's split out the way we expected. We didn't have the right number for test and validation to be exactly equal so there is one more in the validation set but that's not a big deal._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891 534 179 178\n"
     ]
    }
   ],
   "source": [
    "print(len(labels), len(y_train), len(y_val), len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the data\n",
    "\n",
    "_One last step, I'm not going to go over the code here but basically this is just going to print out some summary statistics in the training set, test set, and validation set for each continuous feature. The idea here is that each dataset should be representative of the full data. One way to check that is to make sure that each feature has a very similar distribution across the three datasets_\n",
    "\n",
    "_So taking a quick look at `Pclass` - the mean, standard deviation, first quartile, median, and third quartile are all very similar. You can go down the list for `Age`, etc. and see it's the same for each of them. Now, it would be an issue if we saw the average age in the training set was 17 while the average age in the validation set is 42. However, as long as you have a large enough dataset and it's being split up randomly, you really shouldn't run into any cases like that._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Pclass      Pclass      Pclass\n",
      "count  534.000000  179.000000  178.000000\n",
      "mean     2.337079    2.223464    2.308989\n",
      "std      0.825628    0.864602    0.837017\n",
      "min      1.000000    1.000000    1.000000\n",
      "25%      2.000000    1.000000    2.000000\n",
      "50%      3.000000    3.000000    3.000000\n",
      "75%      3.000000    3.000000    3.000000\n",
      "max      3.000000    3.000000    3.000000\n",
      "              Age         Age         Age\n",
      "count  427.000000  147.000000  140.000000\n",
      "mean    29.284356   30.938231   29.663071\n",
      "std     14.504577   14.608181   14.537967\n",
      "min      0.420000    0.920000    0.830000\n",
      "25%     20.000000   21.000000   20.750000\n",
      "50%     28.000000   29.000000   28.000000\n",
      "75%     37.000000   40.000000   38.250000\n",
      "max     80.000000   71.000000   71.000000\n",
      "            SibSp       SibSp       SibSp\n",
      "count  534.000000  179.000000  178.000000\n",
      "mean     0.588015    0.391061    0.460674\n",
      "std      1.268291    0.736777    0.830984\n",
      "min      0.000000    0.000000    0.000000\n",
      "25%      0.000000    0.000000    0.000000\n",
      "50%      0.000000    0.000000    0.000000\n",
      "75%      1.000000    1.000000    1.000000\n",
      "max      8.000000    4.000000    4.000000\n",
      "            Parch       Parch       Parch\n",
      "count  534.000000  179.000000  178.000000\n",
      "mean     0.370787    0.391061    0.404494\n",
      "std      0.792299    0.843434    0.812600\n",
      "min      0.000000    0.000000    0.000000\n",
      "25%      0.000000    0.000000    0.000000\n",
      "50%      0.000000    0.000000    0.000000\n",
      "75%      0.000000    0.000000    1.000000\n",
      "max      5.000000    5.000000    6.000000\n",
      "             Fare        Fare        Fare\n",
      "count  534.000000  179.000000  178.000000\n",
      "mean    32.712694   32.283613   30.598899\n",
      "std     53.870138   44.888669   40.600757\n",
      "min      0.000000    0.000000    0.000000\n",
      "25%      7.895800    7.987500    7.895800\n",
      "50%     14.454200   15.245800   13.000000\n",
      "75%     30.500000   31.275000   31.130200\n",
      "max    512.329200  262.375000  262.375000\n"
     ]
    }
   ],
   "source": [
    "columns = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n",
    "\n",
    "for c in columns:\n",
    "    print(pd.concat([X_train[c].describe(), X_val[c].describe(), X_test[c].describe()], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
